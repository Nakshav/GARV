import numpy as np
import matplotlib.pyplot as plt

Training_data=[[["","SCORE FOR INT #1", "SCORE for int #2"],["result"]],
               [[1.0,1.00,2.00],[0.0]],
               [[1.0,1.00,2.00],[0.0]],
               [[1.0,1.60,2.53],[0.0]],
               [[1.0,1.47,1.00],[0.0]],
               [[1.0,3.30,2.90],[0.0]],
               [[1.0,3.30,2.90],[0.0]],
               [[1.0,5.60,2.53],[0.0]],
               [[1.0,6.47,7.00],[1.0]],
               [[1.0,7.30,4.90],[1.0]],
               [[1.0,9.30,4.90],[1.0]],
               [[1.0,4.60,5.53],[1.0]],
               [[1.0,1.47,1.00],[0.0]],
               [[1.0,3.30,2.90],[0.0]],
               [[1.0,6.30,4.90],[0.0]],
               [[1.0,1.60,2.53],[0.0]],
               [[1.0,8.47,1.00],[1.0]],
               [[1.0,9.30,9.90],[1.0]],
               [[1.0,8.30,1.90],[1.0]],
               [[1.0,7.78,6.20],[1.0]]]

ALPHA=0.05
Numb_OF_Iterations=1000
class LogisticRegression:
    def gradient_descent(self, x, y):
            w = np.ones((np.shape(x)[1],1))
       
            for i in range(Numb_OF_Iterations):
                 w =  w - ALPHA * x.transpose() * (self.logistic( x * w ) - y)
            return w
    
    def classify(self,x,w):
                prob=self.logistic(sum(x * w))
                classification="prob="+str(prob)+"!!Classified as 0(will not hired)"
                if prob>0.5:
                    classification="prob="+str(prob)+"!!Classified as 1 (will hired)"
                return classification
    def logistic(self, ws): 
        return 1.0 / (1 + np.exp(-ws))

def plot(x, y, w):
    HiredInterviewScore1=[];Hiredinterviewscore2=[]
    NothiredInterviewScore1=[];Nothiredinterviewscore2=[]
    for i in range(0, len(x)):
        if y[i]==0:
            NothiredInterviewScore1.append(x[i][1])
            Nothiredinterviewscore2.append(x[i][2])
        else:
            HiredInterviewScore1.append(x[i][1])
            Hiredinterviewscore2.append(x[i][2])

    ax=plt.figure().add_subplot(1,1,1)
    ax.scatter(HiredInterviewScore1,Hiredinterviewscore2, s=25, c='blue')
    ax.scatter(NothiredInterviewScore1,Nothiredinterviewscore2, s=25, c='red')
    plt.xlabel(Training_data[0][0][1]);plt.ylabel(Training_data[0][0][2])
    interview1score=np.arange(0.0,10.0,0.01)
    interview2score=(-w[0] - w[1] * interview1score) / w[2]
    ax.plot(interview1score,interview2score)
    plt.show()

def handle_command_line():
        flag='true'
        while(flag):
            entry=input("> to classift new candidste enter score:" 
              "for interview 1 & 2 separet by space(for exit):\n")

            if(entry!="exit"):
                score=entry.split()
                print(LogisticRegression.classify([1.0, float(score[0]), float(score[1])], wArray))

            else:
                flag = False
            
LogisticRegression = LogisticRegression();

xArray = []; yArray = []
for i in range(1,len(Training_data) ):
                  xArray.append([Training_data[i][0][0],Training_data[i][0][1],Training_data[i][0][2]])
                  yArray.append(Training_data[i][1][0])
wArray =LogisticRegression.gradient_descent( np.mat(xArray),  np.mat(yArray).transpose() )
print("x Array")
print(wArray)
print("Y tranose ")
print(np.mat(yArray).transpose())
print("close display window to procees:")
plot(xArray,yArray,wArray.getA())
handle_command_line()



