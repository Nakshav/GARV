import numpy as np
impot matplotlib.pyplot as plt
Training_data=[[["","SCORE FOR INT #1", "SCORE for int #2],["result]],
               [[1.0,1.00,2.00],[0.0]],
               [[1.0,2.00,2.00],[0.0]],
               [[1.0,1.60,2.00],[0.0]],
               [[1.0,1.77,2.00],[0.0]],
               [[1.0,2.30,2.00],[0.0]],
               [[1.0,1.78,2.00],[0.0]]]



ALPHA=0.05
Numb_OF_Iterations=1000

class LogisticRegression:

    def gradient_descent(self,x,y):
     w=np.ones((np.shape(x)[1],1))
     for i in range(Numb_OF_Iterations):
w=w-ALPHA*x.transpose()*(self.Logistic(x*w)-y)
return w
   def classify(self,x,w):
    prob=self.Logistic(sum(x*w))

classification="prob="+prob._str_()+"!!Classified as 0(will not hired)"

if prob>0.5:

classification="prob="+prob._str_()+"!!Classified as 1 (will hired)"

return classification

)"


   def Logistic(self,ws);
     return 1.0/(1+np.exp(-ws))

def plot(x,y,w):
hiredInterviewScore=[];hiredinterviewscore2=[]
NothiredInterviewScore=[];Nothiredinterviewscore2=[]


for i in range(0,x._len_()):

if y[i]==0:
NothiredInterviewScore.append(x[i][1])
Nothiredinterviewscore2.append(x[i][2])

else:
hiredInterviewScore.append(x[i][1])
hiredinterviewscore2.append(x[i][2])

ax=plt.figure().add_subplot(1,1,1)
ax.scatter(hiredInterviewScore,hiredInterviewScore2, s=25, c='blue')
ax.scatter(NothiredInterviewScore,NothiredInterviewScore2, s=25, c='red')
plt.xlabel(Training_Data[0][0][1]);ply.ylabel(Training_Data[0][0][2])
interview1score=np.arrabge(0.0,10.0,0.01)
interview2score=(-w[0]-w[1]*interviewscore)/w[2]
ax.plot(interview1score,interview2score)
plt.show()
def handle_comand():
flag='true'
while(flag):
entry=input("> to classift new csndidste enter score:" 
              "for interview 1 & 2 separet by space(for exit):\n")

if(entry!="exit"):
score=entry.split()
print(logisticRegression,classify([1.0, float(score[0]), float(score[1]). wArray))

else:
flag=False




LogisticRegression=LogisticRegression()








xArray=[];
yArray=[];

for i in range(1,Training_data._len_()):
xArray.append([Training_data[i][0][0],Training_data[i][0][1],Training_data[i][0][2]])
yArray.append(Training_data[i][1][0])

wArray=LogisticRegression.gradient_descent(np.mat(xArray), np.mat(yArray).transpose())

print("close display window to procees:")
plot(xArray,yArray,wArray.getA())

handle_command_line()
                